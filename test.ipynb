{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWBh1hoEIzz6uqdlK3s9oL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moosemaniam/IISCDeepLearning/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAJBB9F70J9n",
        "outputId": "da13e022-e1d7-4bfc-a92b-442de3071ca9"
      },
      "source": [
        "!nvidia-smi "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 25 03:07:25 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhjWDAPJ9ZAU",
        "outputId": "e932a56c-63d6-4f14-f6b0-46ead97d6400"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO1MW7pz9d3k",
        "outputId": "f658a7c7-1289-45cc-adc2-b9da2a9d925a"
      },
      "source": [
        "%ls /content/drive/MyDrive/datasets/caltech_data/\n",
        "!unzip /content/drive/MyDrive/datasets/caltech_data/Caltech_256_Train.zip &> /dev/null\n",
        "DRIVE_PATH='/content/drive/MyDrive/datasets/caltech_data/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \u001b[0m\u001b[01;34mcaltech2565.hd5\u001b[0m/                       \u001b[01;34mmodel_10_7.hd5\u001b[0m/\n",
            " \u001b[01;34mcaltech2566.hd5\u001b[0m/                       \u001b[01;34mmodel_20_7.hd5\u001b[0m/\n",
            " \u001b[01;34mcaltech256_7.hd5\u001b[0m/                     'Model information.gsheet'\n",
            " caltech-256-image-classification.zip   submission_22stOct_1118AM.csv\n",
            " Caltech_256_Train.zip                  submission_22stOct_1233.csv\n",
            " \u001b[01;34mcaltech256_v3.hd5\u001b[0m/                     submission_23OCT2021_0728.csv\n",
            " \u001b[01;34mcaltech256_v4.hd5\u001b[0m/                     submission_24OCT2021_2139.csv\n",
            " \u001b[01;34mcaltech256_v6.hd5\u001b[0m/                     \u001b[01;34mtb\u001b[0m/\n",
            " kaggle.json                            tensorboardLogs.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPG22ihD_3JC",
        "outputId": "a40413e9-d84c-4b42-f28e-786ea06790cd"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten,Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau,TensorBoard,EarlyStopping\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "#Constants\n",
        "BATCH_SIZE = 64\n",
        "VALIDATION_SPLIT = 0.1\n",
        "EPOCHS=30\n",
        "VERSION=\"8\"\n",
        "LOAD_VERSION=\"7\"\n",
        "\n",
        "class CustomSaver(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch > 0 and epoch % 5 == 0:  \n",
        "            self.model.save(DRIVE_PATH+\"caltech256_\" + VERSION + \"_EPOCH_\" + str(epoch)+\".hd5\")\n",
        "\n",
        "assert(VERSION != LOAD_VERSION)\n",
        "class Trainer:   \n",
        "    def __init__(self,training_path,batch_size,model_path=None,fineTune=False):\n",
        "        self.callbacks = []\n",
        "    \n",
        "        \n",
        "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                                  patience=5, min_lr=0.0000001)\n",
        "        \n",
        "\n",
        "        tb_callback = TensorBoard(DRIVE_PATH + \"tensorboard/\" + \"model_v{}\".format(VERSION), update_freq=1)\n",
        "        \n",
        "        self.callbacks.append(reduce_lr)\n",
        "        self.callbacks.append(tb_callback)\n",
        "        self.callbacks.append(CustomSaver())\n",
        "\n",
        "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
        "       # self.callbacks.append(es)\n",
        "        self.train_datagen= ImageDataGenerator(rescale=1./255, \n",
        "                                               shear_range=0.2,\n",
        "        zoom_range=0.3,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        rotation_range=40, \n",
        "        fill_mode='nearest',\n",
        "        validation_split=VALIDATION_SPLIT\n",
        "        ) \n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        self.train_generator = self.train_datagen.flow_from_directory(\n",
        "        path_training,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        class_mode='categorical',\n",
        "        subset='training') # set as training data\n",
        "\n",
        "        #Lets document labels in this data set\n",
        "        labels = self.train_generator.class_indices\n",
        "        #Make a dict of labels,class indices\n",
        "        self.labels = dict((v,k) for k,v in labels.items())\n",
        "        \n",
        "        self.validation_datagen= ImageDataGenerator(rescale=1./255,validation_split=VALIDATION_SPLIT )\n",
        "\n",
        "        self.validation_generator = self.validation_datagen.flow_from_directory(\n",
        "        path_training,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        class_mode='categorical',\n",
        "        subset='validation') # set as validation data\n",
        "\n",
        "        if(model_path== None):\n",
        "          #If no model specified load VGG\n",
        "          print(\"Loading VGG + untrained model\")\n",
        "          self.load_VGG16_resized(input_shape=(256,256,3))\n",
        "        else:\n",
        "          print(\"Loading pretrained model from {}\".format(model_path))\n",
        "\n",
        "          \n",
        "          self.model = keras.models.load_model(model_path)\n",
        "          \n",
        "          self.model.summary()\n",
        "          self.add_regularizers_base_model()\n",
        "        return\n",
        "\n",
        "    def add_regularizers_base_model(self):\n",
        "      \"\"\" Add regularizer parameter to pre-trained\n",
        "      model layer. Need to compile again to have effect\"\"\"\n",
        "      #Add regularizer to model https://bit.ly/3GjpodB\n",
        "      self.model.get_layer('vgg16').trainable = True\n",
        "\n",
        "      #Low regularisation coef so that effect of regularisation is minimal\n",
        "      self.model.get_layer('vgg16').kernel_regularizer = keras.regularizers.l2(l2=0.00001)\n",
        "\n",
        "      #Since we are fine-tuning an already trained model, keep learning rate very\n",
        "      #Slow so that base layers don't get affected too much\n",
        "      self.model.compile( loss='categorical_crossentropy',\n",
        "                  optimizer=Adam(learning_rate=0.00001),\n",
        "                  metrics=['acc'])\n",
        "      self.model.summary()\n",
        "      \n",
        "        \n",
        "        \n",
        "    \n",
        "    def load_VGG16_resized(self,input_shape):\n",
        "\n",
        "        #Load VGG16 weights trained on imagenet. Remove classification layer\n",
        "        #At the end\n",
        "        vgg_model = VGG16(weights=\"imagenet\",include_top=False, input_shape=input_shape) \n",
        "        #Make VGG layers non trainable\n",
        "        for layer in vgg_model.layers[:]:\n",
        "            layer.trainable = False\n",
        "\n",
        "        \n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(vgg_model) \n",
        "        self.model.add(Flatten())\n",
        "        self.model.add(Dropout(0.2))\n",
        "        self.model.add(BatchNormalization())\n",
        "        self.model.add(Dense(256, activation='softmax'))\n",
        "        self.model.compile( loss='categorical_crossentropy',\n",
        "                  optimizer=Adam(learning_rate=0.0001),\n",
        "                  metrics=['acc'])\n",
        "        self.model.summary()\n",
        "\n",
        "\n",
        "    def train(self):    \n",
        "\n",
        "        self.history = self.model.fit(\n",
        "          self.train_generator,\n",
        "          steps_per_epoch=\n",
        "             self.train_generator.samples/self.train_generator.batch_size,\n",
        "          epochs=EPOCHS,\n",
        "          validation_data=self.validation_generator,\n",
        "          validation_steps=\n",
        "             self.validation_generator.samples/self.validation_generator.batch_size,\n",
        "          verbose=1,\n",
        "          callbacks=self.callbacks)\n",
        "    def save(self,name):\n",
        "        self.model.save(name)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def predict(self,dataPath):\n",
        "        datagen = ImageDataGenerator(rescale=1./255)\n",
        "        test_generator = datagen.flow_from_directory(\n",
        "        dataPath,\n",
        "        target_size=(256,256),\n",
        "        batch_size=32,\n",
        "        class_mode=None,  # only data, no labels\n",
        "        shuffle=False)\n",
        "        \n",
        "        #This is a num_test_samples X no classes matrix\n",
        "        #With probabilites for each class row wise\n",
        "        probabilities = caltechClassifier.model.predict(test_generator, 1)\n",
        "        \n",
        "        #Get the indices of classes of highest probability\n",
        "        act_pred = np.argmax(probabilities,axis=1)\n",
        "        \n",
        "        #Get labels from class indices\n",
        "        predictions = [self.labels[k] for k in act_pred]\n",
        "        \n",
        "        #Return a tuple of filename and their classes\n",
        "        return(tuple(zip(gen.filenames,predictions)))\n",
        "        \n",
        "        \n",
        "path_training = \"./Caltech_256_Train\"\n",
        "model_path = '/content/drive/MyDrive/datasets/caltech_data/caltech256_v'+ LOAD_VERSION+'.hd5'\n",
        "#model_path = 'model_interim_30.hd5'\n",
        "#model_path='/content/drive/MyDrive/datasets/caltech_data/caltech256_v6.hd5'\n",
        "\n",
        "caltechClassifier = Trainer(training_path=path_training,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            model_path = model_path\n",
        "                            )\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19020 images belonging to 256 classes.\n",
            "Found 1988 images belonging to 256 classes.\n",
            "Loading pretrained model from /content/drive/MyDrive/datasets/caltech_data/caltech256_v7.hd5\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 8, 8, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32768)             131072    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               8388864   \n",
            "=================================================================\n",
            "Total params: 23,234,624\n",
            "Trainable params: 23,169,088\n",
            "Non-trainable params: 65,536\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 8, 8, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32768)             131072    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               8388864   \n",
            "=================================================================\n",
            "Total params: 23,234,624\n",
            "Trainable params: 23,169,088\n",
            "Non-trainable params: 65,536\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TbuZPe-gDxBH",
        "outputId": "a206b297-2df6-4787-c484-e6e0b731985b"
      },
      "source": [
        "caltechClassifier.train()\n",
        "caltechClassifier.model.save(DRIVE_PATH+\"caltech256_v\" + VERSION + \".hd5\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "297/297 [==============================] - 366s 1s/step - loss: 0.8909 - acc: 0.7651 - val_loss: 1.2958 - val_acc: 0.7465\n",
            "Epoch 2/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.8822 - acc: 0.7639 - val_loss: 1.3484 - val_acc: 0.7349\n",
            "Epoch 3/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.8631 - acc: 0.7681 - val_loss: 1.3118 - val_acc: 0.7470\n",
            "Epoch 4/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.8479 - acc: 0.7746 - val_loss: 1.3653 - val_acc: 0.7440\n",
            "Epoch 5/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.8469 - acc: 0.7741 - val_loss: 1.4283 - val_acc: 0.7460\n",
            "Epoch 6/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.8212 - acc: 0.7805 - val_loss: 1.3761 - val_acc: 0.7414\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/datasets/caltech_data/caltech256_8_EPOCH_5.hd5/assets\n",
            "Epoch 7/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.7652 - acc: 0.7935 - val_loss: 1.2836 - val_acc: 0.7535\n",
            "Epoch 8/30\n",
            "297/297 [==============================] - 337s 1s/step - loss: 0.7273 - acc: 0.8022 - val_loss: 1.2934 - val_acc: 0.7560\n",
            "Epoch 9/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.7295 - acc: 0.8043 - val_loss: 1.2894 - val_acc: 0.7601\n",
            "Epoch 10/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.7205 - acc: 0.8066 - val_loss: 1.2713 - val_acc: 0.7596\n",
            "Epoch 11/30\n",
            "297/297 [==============================] - 337s 1s/step - loss: 0.7011 - acc: 0.8103 - val_loss: 1.2671 - val_acc: 0.7586\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/datasets/caltech_data/caltech256_8_EPOCH_10.hd5/assets\n",
            "Epoch 12/30\n",
            "297/297 [==============================] - 337s 1s/step - loss: 0.7250 - acc: 0.8030 - val_loss: 1.2541 - val_acc: 0.7606\n",
            "Epoch 13/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.7181 - acc: 0.8075 - val_loss: 1.3035 - val_acc: 0.7510\n",
            "Epoch 14/30\n",
            "297/297 [==============================] - 337s 1s/step - loss: 0.7059 - acc: 0.8076 - val_loss: 1.2718 - val_acc: 0.7530\n",
            "Epoch 15/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.7011 - acc: 0.8087 - val_loss: 1.2862 - val_acc: 0.7550\n",
            "Epoch 16/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.6941 - acc: 0.8116 - val_loss: 1.2880 - val_acc: 0.7555\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/datasets/caltech_data/caltech256_8_EPOCH_15.hd5/assets\n",
            "Epoch 17/30\n",
            "297/297 [==============================] - 339s 1s/step - loss: 0.6819 - acc: 0.8159 - val_loss: 1.2741 - val_acc: 0.7621\n",
            "Epoch 18/30\n",
            "297/297 [==============================] - 339s 1s/step - loss: 0.6738 - acc: 0.8181 - val_loss: 1.2816 - val_acc: 0.7586\n",
            "Epoch 19/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.6661 - acc: 0.8192 - val_loss: 1.2940 - val_acc: 0.7591\n",
            "Epoch 20/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.6725 - acc: 0.8155 - val_loss: 1.2861 - val_acc: 0.7560\n",
            "Epoch 21/30\n",
            "297/297 [==============================] - 338s 1s/step - loss: 0.6846 - acc: 0.8121 - val_loss: 1.2957 - val_acc: 0.7570\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/datasets/caltech_data/caltech256_8_EPOCH_20.hd5/assets\n",
            "Epoch 22/30\n",
            "275/297 [==========================>...] - ETA: 24s - loss: 0.6773 - acc: 0.8175"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a34520a99fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcaltechClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcaltechClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDRIVE_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"caltech256_v\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mVERSION\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".hd5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-9e717a3292a5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m           callbacks=self.callbacks)\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL9-3ywgzCn1"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at0YQayU4ahP"
      },
      "source": [
        "caltechClassifier.model.save(DRIVE_PATH+\"caltech256_v\" + VERSION + \".hd5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiGX8HFW3XiI",
        "outputId": "ac27e9fa-d557-479d-803e-ed042d5be317"
      },
      "source": [
        "!unzip /content/drive/MyDrive/datasets/caltech_data/caltech-256-image-classification.zip &> /dev/null\n",
        "#Move into a directory structure that makes it easy for image generator to read\n",
        "!mkdir -p caltech_test_data \n",
        "!mv test caltech_test_data\n",
        "!ls caltech_test_data/test | wc -l"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "DbLGKsRP2lsL",
        "outputId": "be529f10-74d6-4be2-86ed-ac1807473af3"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "\n",
        "def predict(model,dataPath):\n",
        "        datagen = ImageDataGenerator(rescale=1./255)\n",
        "        test_generator = datagen.flow_from_directory(\n",
        "        dataPath,\n",
        "        target_size=(256,256),\n",
        "        batch_size=32,\n",
        "        classes=['test'],#Trick the generator into thinking there is only 1 class .. test\n",
        "        shuffle=False)#Shuffle *has* to be false\n",
        "        \n",
        "        #This is a num_test_samples X no classes matrix\n",
        "        #With probabilites for each class row wise\n",
        "        probabilities = model.model.predict(test_generator)\n",
        "        \n",
        "        #Get the indices of classes of highest probability\n",
        "        act_pred = np.argmax(probabilities,axis=1)\n",
        "        \n",
        "        #Get labels from class indices\n",
        "        predictions = [model.labels[k] for k in act_pred]\n",
        " $       cmatrix = confusion_matrix(predictions,model.labels)\n",
        "        \n",
        "        #Return a tuple of filename and their classes\n",
        "        return(tuple(zip(test_generator.filenames,predictions)))\n",
        "results = predict(caltechClassifier,dataPath=\"caltech_test_data\")\n",
        "#sn.heatmap(cmatrix, annot=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9177 images belonging to 1 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-dece136a6d0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#Return a tuple of filename and their classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaltechClassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataPath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"caltech_test_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-dece136a6d0e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, dataPath)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#Get labels from class indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mact_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mcmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#Return a tuple of filename and their classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [9177, 256]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OANk_M3l5c2_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L92PlkTBx9qV"
      },
      "source": [
        "import csv\n",
        "\n",
        "def write_results_to_csv(path,\n",
        "                        results):\n",
        "  with open(path+'submission_25OCT2021_1046.csv','w') as out:\n",
        "      csv_out=csv.writer(out)\n",
        "      csv_out.writerow(['img_path','label'])\n",
        "      for row in results:\n",
        "          csv_out.writerow(row)\n",
        "write_results_to_csv(DRIVE_PATH,results)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Wm_3q59zWd"
      },
      "source": [
        "#Run at the end\n",
        "drive.flush_and_unmount()\n"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}